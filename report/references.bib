@inproceedings{gunson_visually_aware_2022,
  location   = {Edinburgh, {UK}},
  title      = {A Visually-Aware Conversational Robot Receptionist},
  url        = {https://aclanthology.org/2022.sigdial-1.61},
  abstract   = {Socially Assistive Robots ({SARs}) have the potential to play an increasingly important role in a variety of contexts including healthcare, but most existing systems have very limited interactive capabilities. We will demonstrate a robot receptionist that not only supports task-based and social dialogue via natural spoken conversation but is also capable of visually grounded dialogue; able to perceive and discuss the shared physical environment (e.g. helping users to locate personal belongings or objects of interest). Task-based dialogues include check-in, navigation and {FAQs} about facilities, alongside social features such as chit-chat, access to the latest news and a quiz game to play while waiting. We also show how visual context (objects and their spatial relations) can be combined with linguistic representations of dialogue context, to support visual dialogue and question answering. We will demonstrate the system on a humanoid {ARI} robot, which is being deployed in a hospital reception area.},
  eventtitle = {{SIGDIAL} 2022},
  pages      = {645--648},
  booktitle  = {Proceedings of the 23rd Annual Meeting of the Special Interest Group on Discourse and Dialogue},
  publisher  = {Association for Computational Linguistics},
  author     = {Gunson, Nancie and Hernandez Garcia, Daniel and Sieińska, Weronika and Addlesee, Angus and Dondrup, Christian and Lemon, Oliver and Part, Jose L. and Yu, Yanchao},
  urldate    = {2023-01-29},
  date       = {2022-09},
  year       = {2022},
  file       = {Full Text PDF:C\:\\Users\\Laura\\Zotero\\storage\\QGZ39Z8X\\Gunson et al. - 2022 - A Visually-Aware Conversational Robot Receptionist.pdf:application/pdf}
}

@inproceedings{moujahid_multi_party_2022,
  title      = {Multi-party Interaction with a Robot Receptionist},
  doi        = {10.1109/HRI53351.2022.9889641},
  abstract   = {We introduce a situated interactive robot receptionist that can coordinate turn-taking and handle multi-party engagement and dialogue in dynamic environments, where users might enter or leave the scene at any time. The objective is to create a multi-user engagement policy to manage turn-taking using the robot's gaze, head pose, and verbal communication as parameters and to analyse the participant's perception of the robot. Participant feedback on the system was collected using an online survey that allowed for a comparison of subjective feedback for 4 different interaction policies. The results confirm the hypothesis that a robot is perceived as more intelligent and conscious when it reacts using eye gaze or head pose, once a new user enters the scene. Furthermore, we find that robots need to use a combination of verbal and non-verbal cues to coordinate turn-taking, in order to be perceived as polite and aware of human social norms.},
  eventtitle = {2022 17th {ACM}/{IEEE} International Conference on Human-Robot Interaction ({HRI})},
  pages      = {927--931},
  booktitle  = {2022 17th {ACM}/{IEEE} International Conference on Human-Robot Interaction ({HRI})},
  author     = {Moujahid, Meriam and Hastie, Helen and Lemon, Oliver},
  date       = {2022-03},
  keywords   = {multi-party interaction, Robot kinematics, robot receptionist, situated interaction, Social robots},
  year       = {2022},
  file       = {IEEE Xplore Abstract Record:C\:\\Users\\Laura\\Zotero\\storage\\ZW7LIZSK\\stamp.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Laura\\Zotero\\storage\\2JF457KK\\Moujahid et al. - 2022 - Multi-party Interaction with a Robot Receptionist.pdf:application/pdf}
}

@misc{diekmann_1_nodate,
  title   = {1. Slurk: What’s this? — slurk 2.0.0 documentation},
  url     = {https://clp-research.github.io/slurk/slurk_about.html#slurk-about},
  author  = {Diekmann, Tim},
  urldate = {2023-01-30},
  file    = {1. Slurk\: What’s this? — slurk 2.0.0 documentation:C\:\\Users\\Laura\\Zotero\\storage\\W5PFJMDE\\slurk_about.html:text/html}
}

@inproceedings{fernandez_modelling_2008,
  location   = {Columbus, Ohio},
  title      = {Modelling and Detecting Decisions in Multi-party Dialogue},
  url        = {https://aclanthology.org/W08-0125},
  eventtitle = {{SIGDIAL} 2008},
  pages      = {156--163},
  booktitle  = {Proceedings of the 9th {SIGdial} Workshop on Discourse and Dialogue},
  publisher  = {Association for Computational Linguistics},
  author     = {Fernández, Raquel and Frampton, Matthew and Ehlen, Patrick and Purver, Matthew and Peters, Stanley},
  urldate    = {2023-01-30},
  date       = {2008-06},
  file       = {Full Text PDF:C\:\\Users\\Laura\\Zotero\\storage\\LREGUINE\\Fernández et al. - 2008 - Modelling and Detecting Decisions in Multi-party D.pdf:application/pdf}
}

@inproceedings{addlesee_comprehensive_2020,
  location   = {Barcelona, Spain (Online)},
  title      = {A Comprehensive Evaluation of Incremental Speech Recognition and Diarization for Conversational {AI}},
  url        = {https://aclanthology.org/2020.coling-main.312},
  doi        = {10.18653/v1/2020.coling-main.312},
  abstract   = {Automatic Speech Recognition ({ASR}) systems are increasingly powerful and more accurate, but also more numerous with several options existing currently as a service (e.g. Google, {IBM}, and Microsoft). Currently the most stringent standards for such systems are set within the context of their use in, and for, Conversational {AI} technology. These systems are expected to operate incrementally in real-time, be responsive, stable, and robust to the pervasive yet peculiar characteristics of conversational speech such as disfluencies and overlaps. In this paper we evaluate the most popular of such systems with metrics and experiments designed with these standards in mind. We also evaluate the speaker diarization ({SD}) capabilities of the same systems which will be particularly important for dialogue systems designed to handle multi-party interaction. We found that Microsoft has the leading incremental {ASR} system which preserves disfluent materials and {IBM} has the leading incremental {SD} system in addition to the {ASR} that is most robust to speech overlaps. Google strikes a balance between the two but none of these systems are yet suitable to reliably handle natural spontaneous conversations in real-time.},
  eventtitle = {{COLING} 2020},
  pages      = {3492--3503},
  booktitle  = {Proceedings of the 28th International Conference on Computational Linguistics},
  publisher  = {International Committee on Computational Linguistics},
  author     = {Addlesee, Angus and Yu, Yanchao and Eshghi, Arash},
  urldate    = {2023-01-30},
  date       = {2020-12},
  file       = {Full Text PDF:C\:\\Users\\Laura\\Zotero\\storage\\GWN8LYSN\\Addlesee et al. - 2020 - A Comprehensive Evaluation of Incremental Speech R.pdf:application/pdf},
  year       = {2020}
}

@article{gu_who_nodate,
  title    = {Who Says What to Whom: A Survey of Multi-Party Conversations},
  abstract = {Multi-party conversations ({MPCs}) are a more practical and challenging scenario involving more than two interlocutors. This research topic has drawn significant attention from both academia and industry, and it is nowadays counted as one of the most promising research areas in the field of dialogue systems. In general, {MPC} algorithms aim at addressing the issues of Who says What to Whom, specifically, who speaks, say what, and address whom. The complicated interactions between interlocutors, between utterances, and between interlocutors and utterances develop many variant tasks of {MPCs} worth investigation. In this paper, we present a comprehensive survey of recent advances in text-based {MPCs}. In particular, we first summarize recent advances on the research of {MPC} context modeling including dialogue discourse parsing, dialogue flow modeling and selfsupervised training for {MPCs}. Then we review the state-of-the-art models categorized by Who says What to Whom in {MPCs}. Finally, we highlight the challenges which are not yet well addressed in {MPCs} and present future research directions.},
  author   = {Gu, Jia-Chen and Tao, Chongyang and Ling, Zhen-Hua},
  langid   = {english},
  file     = {Gu et al. - Who Says What to Whom A Survey of Multi-Party Con.pdf:C\:\\Users\\Laura\\Zotero\\storage\\6QA79VVG\\Gu et al. - Who Says What to Whom A Survey of Multi-Party Con.pdf:application/pdf}
}

@article{skantze_turn_taking_2021,
  title      = {Turn-taking in Conversational Systems and Human-Robot Interaction: A Review},
  volume     = {67},
  issn       = {0885-2308},
  url        = {https://www.sciencedirect.com/science/article/pii/S088523082030111X},
  doi        = {10.1016/j.csl.2020.101178},
  shorttitle = {Turn-taking in Conversational Systems and Human-Robot Interaction},
  abstract   = {The taking of turns is a fundamental aspect of dialogue. Since it is difficult to speak and listen at the same time, the participants need to coordinate who is currently speaking and when the next person can start to speak. Humans are very good at this coordination, and typically achieve fluent turn-taking with very small gaps and little overlap. Conversational systems (including voice assistants and social robots), on the other hand, typically have problems with frequent interruptions and long response delays, which has called for a substantial body of research on how to improve turn-taking in conversational systems. In this review article, we provide an overview of this research and give directions for future research. First, we provide a theoretical background of the linguistic research tradition on turn-taking and some of the fundamental concepts in theories of turn-taking. We also provide an extensive review of multi-modal cues (including verbal cues, prosody, breathing, gaze and gestures) that have been found to facilitate the coordination of turn-taking in human-human interaction, and which can be utilised for turn-taking in conversational systems. After this, we review work that has been done on modelling turn-taking, including end-of-turn detection, handling of user interruptions, generation of turn-taking cues, and multi-party human-robot interaction. Finally, we identify key areas where more research is needed to achieve fluent turn-taking in spoken interaction between man and machine.},
  pages      = {101178},
  journal    = {Computer Speech and Language},
  author     = {Skantze, Gabriel},
  urldate    = {2023-01-30},
  date       = {2021-05-01},
  langid     = {english},
  keywords   = {Dialogue systems, Gaze, Prosody, Social robotics, Turn-taking},
  file       = {ScienceDirect Full Text PDF:C\:\\Users\\Laura\\Zotero\\storage\\RCQIG5NU\\Skantze - 2021 - Turn-taking in Conversational Systems and Human-Ro.pdf:application/pdf},
  year       = {2021}
}

@inproceedings{porcheron_animals_2017,
  location   = {New York, {NY}, {USA}},
  title      = {"Do Animals Have Accents?": Talking with Agents in Multi-Party Conversation},
  isbn       = {978-1-4503-4335-0},
  url        = {https://doi.org/10.1145/2998181.2998298},
  doi        = {10.1145/2998181.2998298},
  series     = {{CSCW} '17},
  shorttitle = {"Do Animals Have Accents?},
  abstract   = {In this paper we unpack the use of conversational agents, or so-called intelligent personal assistants ({IPAs}), in multi-party conversation amongst a group of friends while they are socialising in a café. {IPAs} such as Siri or Google Now can be found on a large proportion of personal smartphones and tablets, and are promoted as 'natural language' interfaces. The question we pursue here is how they are actually drawn upon in conversational practice? In our work we examine the use of these {IPAs} in a mundane and common-place setting and employ an ethnomethodological perspective to draw out the character of the {IPA}-use in conversation. Additionally, we highlight a number of nuanced practicalities of their use in multi-party settings. By providing a depiction of the nature and methodical practice of their use, we are able to contribute our findings to the design of {IPAs}.},
  pages      = {207--219},
  booktitle  = {Proceedings of the 2017 {ACM} Conference on Computer Supported Cooperative Work and Social Computing},
  publisher  = {Association for Computing Machinery},
  author     = {Porcheron, Martin and Fischer, Joel E. and Sharples, Sarah},
  urldate    = {2023-01-30},
  date       = {2017-02-25},
  keywords   = {collocated interaction, conversation analysis, conversational agents, ethnomethodology, intelligent personal assistants, mobile devices, multi-party conversation, smartphones},
  file       = {Accepted Version:C\:\\Users\\Laura\\Zotero\\storage\\REB87W6W\\Porcheron et al. - 2017 - Do Animals Have Accents Talking with Agents in.pdf:application/pdf}
}

@inproceedings{cooper_ari_2020,
  title      = {{ARI}: the Social Assistive Robot and Companion},
  doi        = {10.1109/RO-MAN47096.2020.9223470},
  shorttitle = {{ARI}},
  abstract   = {With the world population aging and the number of healthcare users with multiple chronic diseases increasing, healthcare is becoming more costly, and as such, the need to optimise both hospital and in-home care is of paramount importance. This paper reviews the challenges that the older people, people with mobility constraints, hospital patients and isolated healthcare users face, and how socially assistive robots can be used to help them. Related promising areas and limitations are highlighted. The main focus is placed on the newest {PAL} Robotics’ robot: {ARI}, a high-performance social robot and companion designed for a wide range of multi-modal expressive gestures, gaze and personalised behaviour, with great potential to become part of the healthcare community by applying powerful {AI} algorithms. {ARI} can be used to help administer first-care attention, providing emotional support to people who live in isolation, including the elderly population or healthcare users who are confined because of infectious diseases such as Covid-19. The {ARI} robot technical features and potential applications are introduced in this paper.},
  eventtitle = {2020 29th {IEEE} International Conference on Robot and Human Interactive Communication ({RO}-{MAN})},
  pages      = {745--751},
  booktitle  = {2020 29th {IEEE} International Conference on Robot and Human Interactive Communication ({RO}-{MAN})},
  author     = {Cooper, Sara and Di Fava, Alessandro and Vivas, Carlos and Marchionni, Luca and Ferro, Francesco},
  date       = {2020-08},
  note       = {{ISSN}: 1944-9437},
  keywords   = {{COVID}-19, Hospitals, Infectious diseases, Sociology, Statistics, Surgery, User experience},
  year       = {2020},
  file       = {IEEE Xplore Abstract Record:C\:\\Users\\Laura\\Zotero\\storage\\8VJEILTT\\stamp.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Laura\\Zotero\\storage\\35CYUM9Q\\Cooper et al. - 2020 - ARI the Social Assistive Robot and Companion.pdf:application/pdf}
}

@misc{Health_workforce_2023,
  url          = {https://www.who.int/health-topics/health-workforce},
  title        = {Global Health Workforce Statistics},
  author       = {WHO},
  abstractnote = {Health systems can only function with health workers; improving health service coverage and realizing the right to the enjoyment of the highest attainable standard of health is dependent on their availability, accessibility, acceptability and quality.},
  language     = {en},
  note         = {Accessed on: 2023-02-07},
  year         = {2023}
}

@misc{palrobot,
  title    = {ARI - The social and collaborative robot},
  url      = {https://pal-robotics.com/robots/ari/},
  author   = {Pal Robotics},
  language = {en-US},
  year     = {2023},
  note     = {Accessed on: 2023-02-08}
}

@article{Żarkowski_2019,
  title        = {Multi-party Turn-Taking in Repeated Human–Robot Interactions: An Interdisciplinary Evaluation},
  volume       = {11},
  issn         = {1875-4805},
  doi          = {10.1007/s12369-019-00603-1},
  abstractnote = {As social robots become more popular, so arises the need for these social agents to operate in environments involving multiple users. The robot control systems that govern these multi-party interactions require to be evaluated both from the technical and social standpoints. This paper presents the methodology, setup and results for experiment involving the social robot EMYS participating in multi-party interaction where pairs of participants interacted with the robot in a trivia questions game lead by the robot . In total 32 people, 16 pairs, interacted with the robot twice, which resulted in 32 interactions and 64 filled questionnaires. The developed robot’s multi-party interaction system was evaluated both in terms of performance and user assessment. The results show that the robot adhering to human turn-taking social norms reduced the number of occurring conversational errors, which improved the communicative performance from $$51.5%$$ to $$80.5%$$, in addition, it made the robot perceived as more communicative, cooperative and fitting user expectations by up to 3 points on a 7 point scale. In addition, the study on repeated interactions revealed that user perception of the robot is affected by subsequent interactions, which can be of consequence in future experiments. This first impression caused lasting effect between 1 and 2 points on user assessment of several robot’s aspects, even when contradicted by objective performance measurement of the robot’s actual behavior.},
  number       = {5},
  journal      = {International Journal of Social Robotics},
  author       = {Żarkowski, Mateusz},
  year         = {2019},
  month        = {Dec},
  pages        = {693–707},
  language     = {en}
}

@inproceedings{Johansson_Skantze_2015,
  address   = {Prague, Czech Republic},
  title     = {Opportunities and Obligations to Take Turns in Collaborative Multi-Party Human-Robot Interaction},
  url       = {https://aclanthology.org/W15-4642},
  doi       = {10.18653/v1/W15-4642},
  booktitle = {Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
  publisher = {Association for Computational Linguistics},
  author    = {Johansson, Martin and Skantze, Gabriel},
  year      = {2015},
  month     = {Sep},
  pages     = {305–314}
}

@misc{Group_1_unpublished_paper,
  url    = {https://heriotwatt.sharepoint.com/sites/F20DV-CollaborativeQuizProject/Shared%20Documents/Forms/AllItems.aspx?FolderCTID=0x012000C31DB7E9EEFD0240A1EA2B93F809CD1B&id=%2Fsites%2FF20DV%2DCollaborativeQuizProject%2FShared%20Documents%2FGeneral%2Faddlesee%2Diwsds%2Dmpc%2Epdf&parent=%2Fsites%2FF20DV%2DCollaborativeQuizProject%2FShared%20Documents%2FGeneral},
  year   = {2023},
  author = {Angus Addlesee and Weronika Sieinska and Nancie Gunson and Daniel Hernández García and Christian Dondrup and Oliver Lemon}
}

@article{Cohen_1960,
  title     = {A Coefficient of Agreement for Nominal Scales},
  volume    = {20},
  issn      = {0013-1644},
  doi       = {10.1177/001316446002000104},
  number    = {1},
  journal   = {Educational and Psychological Measurement},
  publisher = {SAGE Publications Inc},
  author    = {Cohen, Jacob},
  year      = {1960},
  month     = {Apr},
  pages     = {37–46},
  language  = {en}
}
@article{McHugh_2012,
  title        = {Interrater reliability: the kappa statistic},
  volume       = {22},
  issn         = {1330-0962},
  abstractnote = {The kappa statistic is frequently used to test interrater reliability. The importance of rater reliability lies in the fact that it represents the extent to which the data collected in the study are correct representations of the variables measured. Measurement of the extent to which data collectors (raters) assign the same score to the same variable is called interrater reliability. While there have been a variety of methods to measure interrater reliability, traditionally it was measured as percent agreement, calculated as the number of agreement scores divided by the total number of scores. In 1960, Jacob Cohen critiqued use of percent agreement due to its inability to account for chance agreement. He introduced the Cohen’s kappa, developed to account for the possibility that raters actually guess on at least some variables due to uncertainty. Like most correlation statistics, the kappa can range from -1 to +1. While the kappa is one of the most commonly used statistics to test interrater reliability, it has limitations. Judgments about what level of kappa should be acceptable for health research are questioned. Cohen’s suggested interpretation may be too lenient for health related studies because it implies that a score as low as 0.41 might be acceptable. Kappa and percent agreement are compared, and levels for both kappa and percent agreement that should be demanded in healthcare studies are suggested.},
  number       = {3},
  journal      = {Biochemia Medica},
  author       = {McHugh, Mary L.},
  year         = {2012},
  month        = {Oct},
  pages        = {276-282}
}  
@article{Sun_2011,
  title   = {Meta-analysis of Cohen's kappa},
  url     = {https://link.springer.com/content/pdf/10.1007/s10742-011-0077-3.pdf},
  year    = {2011},
  author  = {Sun, Shuyan},
  doi     = {10.1007/s10742-011-0077-3},
  journal = {Springer}
}
  
  
>>>>>>> fed5696e108b93b70175904bda10c6aa51823905
