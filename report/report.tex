%
% File acl2016.tex
%
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{acl2016}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}

\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}

\title{Instructions for ACL-2016 Proceedings}

\author{Tom Byars, Cale Clark, Roman Fenlon, Charlie Lyttle, Katie McAskill, Jack Miller, Zein Said, \\
{\bf Abdullah Sayed, Laura Schauer, Jason Sweeney, Aron Szeles, Xander Wickham} \\
School of Mathematics and Computer Science, Heriot-Watt University, Edinburgh \\ {\tt {tjb10, cc164, rf104, cl157, klm12, jjm7, zs2008,}} \\ {\tt {as512, lms9, js418, as472, aw127}@hw.ac.uk}}

\date{February 2023}

\begin{document}
\maketitle
\begin{abstract}
  This should be a 6-8 page conference paper with appendices, if relevant. 
\end{abstract}


\section{Introduction}
\label{sec:introduction}

\textit{from coursework spec:} main research or technical question addressed \\
Socially assistive robots (SARs) are a crucial part of the future of many sectors, for example, in education or healthcare \cite{gunson_visually_aware_2022}. Especially the latter depends on technology advancements as it is facing numerous obstacles in the future, such as increasing spendings and a growing percentage of older people. A serious lack of healthcare workers is already occurring, with 10 million more healthworkers needed worldwide by 2030 \cite{cooper_ari_2020,Health_workforce_2023}. SARs can pose a solution to the problem, as they are able to support healthcare in various ways, such as encouraging older people to keep living independently for longer or reducing caregiver burden \cite{cooper_ari_2020}.

These scenarios require SARs to be able to handle multi-party interactions as it is likely that more than one person will interact with the system. Compared to handling dyadic interactions, handling multi-party conversations includes more complex challenges, such as Speaker Recognition, Addressee Recognition, Response Selection (summarised in “who says what to whom“) and turn-taking \cite{Group_1_unpublished_paper,Johansson_Skantze_2015}. 

\textit{Include here what exactly we examined about turn-taking}

In this work, we propose a model trained on multi-party human-human conversation data. We collected the data from recordings of special “Who wants to be millionaire?“ episodes where two candidates collaborated to answer the host's questions.

\textit{Include results here.}


\section{Background}
\label{sec:background}

\textit{from coursework spec:} literature review / related work, including a critical analysis of the field, and commentary on applicability of the technologies and methods used in emerging technologies and application areas

\subsection{Socially Assistive Robots}
\label{subsec:socially_assistive_robots}
The difficulty of designing successful SARs lies in creating robots that can effectively converse with humans and adhere to social norms \cite{moujahid_multi_party_2022}. The more expressive a robot is, the more it will be perceived as intelligent, conscious and polite \cite{moujahid_multi_party_2022}. To achieve such a positive perception, multiple parts need to be combined into one conversational system, such as the ability to carry out visually grounded as well as task-based dialogues, to perceive and discuss its environment and to chit-chat \cite{gunson_visually_aware_2022}.

Research concerning such a system has been conducted on a SAR robot deployed in an eldercare hospital reception area in the course of the SPRING research project \cite{addlesee_comprehensive_2020}. SPRING-ARI is deployed on a humanoid robot, called ARI, produced by Pal Robotics \cite{palrobot}. The design of ARI is focused on a few key factors: mobility, lightness, safety, simplicity, and modernity \cite{cooper_ari_2020}. The particular robot which is used for SPRING-ARI is equipped with a touch screen on its torso, gaze control through LCD eyes (liquid crystal display eyes) and 360° view. Its capabilities can be extended with custom AI algorithms, in the case of SPRING-ARI a visual perception system, a dialogue system, and a social interaction planner \cite{addlesee_comprehensive_2020}. While the SPRING-ARI system successfully demonstrates that task-based, social and visually grounded dialogue can be combined with physical actions, it still lacks the ability to handle conversations with more than one person simultaneously \cite{addlesee_comprehensive_2020}.

\subsection{Multi-party Human Robot Interaction}
\label{subsec:multi_party}
As stated above, this endeavour becomes considerably more difficult when dealing with multi-party interactions \cite{Group_1_unpublished_paper}. Especially turn-taking poses a central problem. It is defined as follows: 

\begin{quote}
  The rules of turn-taking organize the conversation into turns, during which one of the participants has the right to speak while the others agree to listen \cite{Żarkowski_2019}
\end{quote}

In dyadic conversations, there are only two roles a participant can take: speaker or listener, hence it is clear when and to whom the turn is yielded. In multi-party conversations, participants can take multiple roles, therefore turn-taking needs to be coordinated \cite{Johansson_Skantze_2015}. Research has found that humans signal their intents mostly through gaze, but also through pauses, prosody, and body positioning \cite{Żarkowski_2019}. Earlier models for conversational systems relied on silence time-outs to coordinate turn-taking, however, this approach is found to be too simplistic \cite{skantze_turn_taking_2021}. Using 



\section{Design and Implementation}
\label{sec:implementation}

\textit{from coursework spec:} design and implementation of the system: components and architecture

\subsection{State-of-the-art Tools}
\label{subsec:tools}
\textit{Explain what tools we'll be using}


\section{Evaluation}
\label{sec:evaluation}

\textit{from coursework spec:} evaluation of the system and presentation of the results


\section{Future Work}
\label{sec:future_work}

\textit{from coursework spec:} suggestions for future work


\section*{Acknowledgments}
\label{sec:acknowledgments}

The acknowledgments should go immediately before the references.  Do
not number the acknowledgments section. Do not include this section
when submitting your paper for review.

% include your own bib file like this:
%\bibliographystyle{acl}
%\bibliography{acl2016}
\bibliography{references}
\bibliographystyle{acl2016}

\appendix

\section{Supplemental Material, Appendix}
\label{sec:supplemental}


\end{document}
