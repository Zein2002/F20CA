%
% File acl2016.tex
%
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[hidelinks, 11pt]{article}
% for table colouring 
% \usepackage[table]{xcolor}
\usepackage[table]{xcolor}
\usepackage{acl2016}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}

% for todo notes 
\usepackage{todonotes}

% maths
\usepackage{amssymb}
% cool maths printing
\usepackage{amsmath}

\usepackage[hidelinks]{hyperref}
% For referencing sections across the article
\usepackage{cleveref}

\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}
% To add some line spacing in the table
\renewcommand{\arraystretch}{1.3}

\title{Instructions for ACL-2016 Proceedings}

\author{Tom Byars, Cale Clark, Charlie Lyttle, Katie McAskill, Jack Miller, Zein Said, \\
{\bf Abdullah Sayed, Laura Schauer, Jason Sweeney, Aron Szeles, Xander Wickham} \\
School of Mathematics and Computer Science, Heriot-Watt University, Edinburgh \\ {\tt {tjb10, cc164, cl157, klm12, jjm7, zs2008,}} \\ {\tt {as512, lms9, js418, as472, aw127}@hw.ac.uk}}

\date{February 2023}

\begin{document}
\maketitle
\begin{abstract}
  This should be a 6-8 page conference paper with appendices, if relevant.
  Good reports from last year: 1 and 7
\end{abstract}


\section{Introduction}
\label{sec:introduction}

\textit{from coursework spec:} main research or technical question addressed \\
Socially assistive robots (SARs) are a crucial part of the future of many sectors, for example, education or healthcare \cite{gunson_visually_aware_2022}. Especially the latter depends on technology advancements as it is facing numerous obstacles in the future, such as increasing spendings and a growing percentage of older people. A serious lack of healthcare workers is already occurring, with 10 million more healthworkers needed worldwide by 2030 \cite{cooper_ari_2020,Health_workforce_2023}. SARs can pose a solution to the problem by supporting healthcare in various ways, such as encouraging older people to keep living independently for longer or reducing caregiver burden \cite{cooper_ari_2020}.

Healthcare SAR scenarios require SARs to be able to handle multi-party interactions as it is likely that more than one person will interact with the system. Compared to handling dyadic (two-party) interactions, handling multi-party conversations includes more complex challenges, such as Speaker Recognition, Addressee Recognition, Response Selection (summarised in “who says what to whom“) and coordination of turn-taking \cite{Group_1_unpublished_paper,Johansson_Skantze_2015}.

\textit{Include here what exactly we examined about turn-taking}

In this work, we propose a conversational system using a model trained on multi-party human-human conversation data. We collected the data from recordings of special “Who wants to be millionaire?“ episodes where two candidates collaborated to answer the host's questions.

\textit{Include results here.}


\section{Background}
\label{sec:background}

\textit{from coursework spec:} literature review / related work, including a critical analysis of the field, and commentary on applicability of the technologies and methods used in emerging technologies and application areas

\subsection{Socially Assistive Robots}
\label{subsec:socially_assistive_robots}
For healthcare, as well as for any other sector, the difficulty of successfully designing SARs lies in creating robots that can effectively converse with humans and adhere to social norms \cite{moujahid_multi_party_2022}. The more expressive a robot is, the more it will be perceived as intelligent, conscious and polite \cite{moujahid_multi_party_2022}. To achieve such a positive perception, multiple parts need to be combined into one conversational system, such as the ability to carry out visually grounded as well as task-based dialogues, to perceive and discuss its environment and to chit-chat \cite{gunson_visually_aware_2022}.

The SPRING project conducts research on a SAR robot deployed in an eldercare hospital reception area \cite{addlesee_comprehensive_2020}. The conversational system is deployed on the humanoid ARI robot produced by Pal Robotics \cite{palrobot}. ARIs capabilities can be extended with custom AI algorithms, in the case of SPRING-ARI a visual perception system, a dialogue system, and a social interaction planner \cite{addlesee_comprehensive_2020}. While the SPRING-ARI system successfully demonstrates that task-based, social and visually grounded dialogue can be combined with physical actions, it still lacks the ability to handle conversations with more than one person simultaneously \cite{addlesee_comprehensive_2020}.

\subsection{Multi-party Human Robot Interaction}
\label{subsec:multi_party}
As stated before, the endeavour to create conversational systems becomes considerably more difficult when dealing with multi-party interactions \cite{Group_1_unpublished_paper}. Especially turn-taking poses a central problem. It is defined as follows:

\begin{quote}
  The rules of turn-taking organize the conversation into turns, during which one of the participants has the right to speak while the others agree to listen. \cite{Żarkowski_2019}
\end{quote}

In dyadic conversations, there are only two roles a participant can take: speaker or listener, hence it is clear when and to whom the turn is yielded. In multi-party conversations, participants can take multiple roles, therefore turn-taking needs to be coordinated \cite{Johansson_Skantze_2015}. Humans signal their intents mostly through gaze, but also through pauses, prosody, and body positioning \cite{Żarkowski_2019}. To copy this behaviour, earlier models for conversational systems relied on silence time-outs to coordinate turn-taking, however, this approach is found to be too simplistic \cite{skantze_turn_taking_2021}. Instead, mimicking human turn-taking behaviour better by using a combination of verbal and non-verbal cues leads to robots that are better perceived \cite{moujahid_multi_party_2022}.

\textit{State exactly the gap that we will fill - whatever that will be}


\section{Data Collection}
\label{sec:data_collection}

\begin{itemize}
  \item (Laura) Talk about multi-party data collection
\end{itemize}

Data collection was performed by the team. We first collected all available recordings of ``Who Wants to Be a Millionaire'' with two participants, which were transcribed using the YouTube API. To annotate these transcripts, we used the unified set of annotations shown in \Cref{table:intents}. This list allows us to capture as much information as possible, without saturating the data.

\noindent
\begin{table}
  \begin{tabular}{ | p{2.5cm} | p{5cm} | }
    \hline
    \rowcolor{lightgray}
    Intent               & Description                                                              \\
    \hline
    question             & The system presents the question                                         \\
    \hline
    options              & The system presents the options                                          \\
    \hline
    chit-chat            & Speech not related to the quiz                                           \\
    \hline
    offer-answer()       & A player presents an answer to the other player                          \\
    \hline
    offer-to-answer      & A  player signals that they know the answer                              \\
    \hline
    agreement            & Agreement between players about the answer                               \\
    \hline
    ask-agreement        & A player asks the other player for confirmation on their proposed answer \\
    \hline
    accept-answer        & System considers answer the final answer                                 \\
    \hline
    final-answer()       & Players give final answer                                                \\
    \hline
    confirm-agreement    & The system tries to confirm the final answer with participants           \\
    \hline
    confirm-final-answer & Participants confirm their answer is final                               \\
    \hline
  \end{tabular}
  \caption{Intents used for Data Annotation}
  \label{table:intents}
\end{table}

\subsection{Cohen's Kappa Coefficient}
To ensure reliability and consistency, Cohen's kappa was calculated for a sample of the completed transcripts. It measures the reliability between raters on categorical data, while accounting for agreement happening by chance \cite{Cohen_1960}. A sample of four transcripts are re-annotated by a team member, which amounts to approximately 15\% of the total transcripts.

% Every occurrence by both raters of each annotation label was gathered. An overall agreement rate was calculated using -

% \begin{equation} \label{eq:kappa}
%   \begin{split}
%     Agreement & = \frac{total \: Agreed}{total} \\
%     % Agreement & = \frac{329}{341} \\
%     Agreement & = \underline{\underline{0.9684}}
%   \end{split}
% \end{equation}

% This alone is not reliable enough to trust.\cite{Sun_2011} To calculate the chance of an agreement happening between the two raters, first the probability of a rater choosing a label is calculated. This is done for each rater for every label using -

% \begin{equation}
%   Prob(R_x[label]) = \frac{R_x \: Total \: for \: [label]}{total}
% \end{equation}

% Then the chance of agreement for each annotation label is calculated using -

% \begin{equation}
%   \begin{split}
%     &ChanceAgreement[label] = \\
%     &Prob(R_1[label]) * Prob(R_2[label])
%   \end{split}
% \end{equation}

% The overall chance of agreement is calculated by summing the chance of agreements for each annotation label.

% Finally, the kappa score is calculated.

\begin{equation}
  \begin{split}
    KappaScore & = \frac{Agree - ChanceAgree}{1 - ChanceAgree} \\
    KappaScore & = \underline{\underline{0.9601}}
  \end{split}
\end{equation}

\noindent
A Kappa score of 0.9601 is interpreted as ``almost perfect agreement'' \cite{McHugh_2012}. From this, the annotation of transcripts can be concluded as reliable.

\section{Design and Implementation}
\label{sec:implementation}

Our conversational system consists of several parts, the modular architecture is shown in \Cref{fig:system_architecture}. This section outlines each module and describes how our system manages the process from the users' utterances to the system's response.

\begin{figure}
  \includegraphics*[width=\columnwidth]{images/system_graph.png}
  \caption{Architecture of the conversational system}
  \label{fig:system_architecture}
\end{figure}

\subsection{Automatic Speech Recognition}
\label{subsec:asr}

The first step is to transform user's speech into text, in order to pass text further onto intent recognition (NLU). Transforming audio into text works through Speech-To-Text (STT) software. In recent years, STT systems have become more accurate and fast, however, none of the existing systems can yet reliably handle conversations in real time \cite{addlesee_comprehensive_2020}.

Our conversational system required two non-standard aspects from the ASR: (1) real-time transcription and (2) diarization. As our system conceptualised for usage on a robot, it must transcribe what the user is saying in real-time to avoid response delays. Time taken for a system to respond can only be marginally longer than the delay a human would leave before responding \todo{source!}.

Diarization is the process of determining the speaker in multi-party conversations. Therefore, to handle a ``Who wants to be millionaire?'' style game, our system must be able to diarise. This allows us to track the intents of each individual user and determine when users agree or disagree.
We tried several STT systems including Amazon's Transcribe, IBM's Watson and locally running Pyannote. Our findings were that these are all valid options for transcription but lack real-time diarization. We settled with Google's Cloud Speech-to-Text API due to its high accuracy, real-time transcription capabilities, and customisability. As it is widely used, troubleshooting and integration resources were readily available. In addition, Google's API promised diarization capabilities, which, along with its real-time transcription capabilities seemed to fit our use case. However, in use, diarization was inaccurate, and it often grouped two separate speakers together or split sentences up seemingly at random. This became even more apparent when two users were speaking over each other, supporting the findings of \cite{addlesee_comprehensive_2020}. As this made Google's diarization unusable for our system, we decided to move to a set-up with two microphones (one for each user) and integrate them with the real time Google transcription.

\subsection{Natural Language Understanding}
\label{subsec:nlu}

Natural Language Understanding (NLU) takes in utterances of natural human language and classifies them into intents that a computer can use. RASA is an open-source framework for building conversational systems. We used its NLU tool to train on our collected data, after cleaning it \todo{word better}. RASA NLU successfully created a model that can accurately recoginize new, unseen inputs, which are similar to the training examples. The phrases transcribed in the ASR component are passed on to the NLU model, which will label them with one of the intents from \Cref{table:intents} and pass this information onto the Dialogue Management part.

% \begin{quote}
%   Rasa Open Source is the most popular open source framework for building chat and voice-based AI assistants. Rasa Open Source is an open source conversational AI platform that allows you to understand and hold conversations, and connect to messaging channels and third party systems through a set of APIs. It supplies the building blocks for creating virtual (digital) assistants or chatbots.
% \end{quote}

% We are not using all that Rasa has to offer but only Rasa NLU. Rasa NLU only produces a NLU model that can translate human language into intents or labels without the rest of the conversational system like DM and NLG. It takes training data in the form of each intent required with examples of natural language that would be classified under that intent.

The model is also capable of entity extraction, which means it can recognize and label words of interest. In our case, we use entity extraction to find and label the answer to the question or a rejected answer given in an utterance \todo{add an example of this}.

\subsection{Evaluation of NLU}
\label{subsec:NLU_evaluation}

The NLU model has gone through multiple iterations, starting with very few training examples and being highly innacurate to a large amount of clean data producing a highly accurate and reliable model. Two models and their evaluations:

\paragraph{Original} The original model is the first model trained on only 4 or 5 annotated transcripts, very little training data.
This model was highly innacurate, constantly mislabeling intents, and extracting wrong answers or no answer at all.
The Rasa training model used was not very efficient with a small amount of training data so this was expected.

\begin{figure}
  \includegraphics[width=\columnwidth]{../Rasa/Evaluation/Original_Model/DIETClassifier_confusion_matrix.png}
\end{figure}

The diagram above shows the entity extraction confusion matrix, where you can see that more than half of the phrases with answers werent extracted.
It did well with phrases without entities and rarely mislabed entities that werent actually answers, but its general tendency to not extract an entity was poor.

\begin{figure}
  \includegraphics[width=\columnwidth]{../Rasa/Evaluation/Original_Model/intent_confusion_matrix.png}
\end{figure}

This diagram shows the confusion matrix for the intents.
It shows a random scatter over the matrix meaning that the predicted labels and real labels often did not match up.
The model in general was quite random and inconsistent to say the least.

\paragraph{Used Model} The latest/best model, and the one actually used in our chatbot, was trained on around 25 transcripts with hundreds of training examples for each intent. Furthermore, we went through all the training data and manually cleaned it of any examples that were misplaced or extracted from the transcripts wrong. The added amount of data and the cleaning proved to do wonders as the performance of the model was much more reliable and accurate.

\begin{figure}
  \includegraphics[width=\columnwidth]{../Rasa/Evaluation/Clean_Model/DIETClassifier_confusion_matrix.png}
\end{figure}

As can be seen above, the confusion matrix is perfect as the model did not make any mistakes with entity extraction. Of course the model can't be perfect and this is only its performance on our test data, but still a crystal clear difference from the original model.

\begin{figure}
  \includegraphics[width=\columnwidth]{../Rasa/Evaluation/Clean_Model/intent_confusion_matrix.png}
\end{figure}

This diagram again shows the intents and how much more accurate this model is compared to the original. It only has a few mistakes here and there, especially with the more ambiguous intents, but even us as humans confuse those intents often. Regardless, the model is leaps more accurate than its beginning.

\begin{itemize}
  \item Short description of RASA
  \item Explain the aim (detecting intents)
  \item Refer to the intents described in \ref{sec:data_collection} \cref{sec:data_collection}
  \item Evaluation - show different versions of the model: difference in F-Score, Confusion Matrix, ...
\end{itemize}

\subsection{Dialogue Management}
\label{subsec:dialogue_management}

The dialogue manager is composed of two components: a state machine and a Pytorch model running on top of it. This approach was chosen because, despite involving a conversation which requires intelligent behaviour from the dialogue manager, the game itself is defined by a rigid set of rules. There are ten questions, the conversation must see the system pass from each question to the next, and the game must end at a specified time. Running the model on top of the hard-coded logic of the state machine can ensure that this movement from state to state is observed. \todo{reword "running the model on top of"}

\subsubsection{Neural Network - Cale}
\label{subsec:nn}
The neural network model was designed to manage dialogue for a three-person conversation. To do this, it has two inputs, the intent (decided by the NLU) and the user ID (user 1, user 2 or host). These inputs were both one-hot encoded, the intent being a vector of size 14 (one for each intent) and the user number being a vector of size 3. These two vectors were concatenated to produce an input vector of size 17. The network was then trained to predict the host's response for a given intent and user in a sequence. This output is a vector of size 5, one for each of the 4 system intents plus one for \verb|no response|.

The model was trained using the dataset which we had originally labelled for NLU purposes. This provided human labelled sequences of intents and user IDs for each question. Each question would have its intents and user IDs input into the network sequentially, with the model's memory being cleared after every question. Every output from the system which is not \verb|no response| would be input back into the network, allowing for the system to speak multiple lines of dialogue in succession. At the start of each question, the system is set up by first inputting the host having given the \verb|question| intent, to which it will always output the \verb|options| intent. This is required since every question in the training data is started by the host asking the question, then giving the options for the question.

The primary difficulty of training was the imbalance in the dataset. Since most of the time, the host will be only listening, \verb|no response| is by far the most common output. This means that having the output as a single SoftMax vector of size 5 would be difficult, as the model would quickly learn to always output \verb|no response|. Traditional undersampling and oversampling methods would also be difficult to make use of, since the \verb|no response| output exists as part of a real conversation, which must be fed into the network sequentially. For example, uncommon system responses could not be oversampled, as they exist as part of a real question, most of which is often filled with \verb|no response| from the host. Artificially increasing their frequency could not be done without altering the questions, which would diminish the integrity of the data.

To overcome this, a separate Sigmoid output was used for \verb|no response| (as shown in the diagrams above). To train this model, whenever \verb|no response| from the host was expected, the loss from the SoftMax vector was set to zero, otherwise L2 loss was used for all outputs. The system was implemented in PyTorch, with the model being trained for 30 epochs with a learning rate of 5x10-4.

In future, this architecture could be used for handling multi-person dialogues with more intents or more users by simply scaling the inputs, outputs, and hidden layers accordingly. The model could also be altered to allow for more inputs such as pauses or other non-verbal cues.

\subsubsection{Dialogue Manager - Jack}
\label{subsec:dm}

The intent detected by the NLU system from a user's utterance is passed to the dialogue manager from where it is input into the PyTorch model. The model then decides on an appropriate action. The state machine checks if the output from the PyTorch model represents a sensible action. In case there are logical errors, the output will be overridden. For example, if the NLU detects that the user intends to confirm final answer, but no answer has yet been given, the PyTorch model may nonetheless decide on \verb|accept-answer|. As no answer has been given set, the state machine will overwrite this output.

Another reason for using the state machine was the limited transcript data. The PyTorch model learned off of the transcript data. There are user intents found throughout the transcripts, followed by a certain action (or no action). Therefore, the PyTorch model depended on a sufficient amount of transcript data to function adequately. Using a state machine allowed us to program explicitly how the chatbot is meant to respond to user intents, thus eliminating the need for so more transcript data.

The state machine's configuration is defined inside a JSON file \todo{insert Jack's figure}. When the action decided by the chatbot is overridden by the state machine, it is done according to this configuration. The action chosen by the state machine is a string of JavaScript code, and is found in the configuration object \verb|flow| at \verb|flow[state][intent]|, where \verb|state| is the current state of the machine and \verb|intent| is the name of the most recent user intent.

Throughout the course of a game, the dialogue manager stores relevant values, such as answers offered by the user, and these values also influence the behaviour of the state machine. An example of this can be found inside the `seek-confirmation` state when the host asks the users if they would like to lock in an answer suggested by them. If a user responds by rejecting the answer they had just given, then the host will check to see if the answer they are rejecting is the same as the answer that they had just offered. If it is, then the host will assume that they are not wishing to lock in that answer. However, if the answer being rejected by the user is another one, then the host will assume that they do indeed wish to proceed with their offered answer.

A more secure approach to this situation would involve taking a record of all the answers ruled out by the users. The host would then lock in a final answer after a rejected answer if and only if the other two possible answers had also been previously rejected. We would take in a future implementation as it would reduce the risk of the host accepting answers while the users are still deciding.

\subsubsection{Xander}
\label{subsec:xander}
Recurrent Neural Networks and Long-Short Term Memory are the two types of Neural Network that have been used throughout the project due the fact that they use context when calculating the outcomes of the Neural Network. A Neural Network has multiple hidden layers each has its own weights and bias. This causes each layer has this they act independently, which is not helpful when trying to identify a pattern between the successive inputs. RNN will have the same weights and bias for the hidden layers, but will supply the a state to each neuron. This state is then used to link the next input to form the next state.
However, the issue with this is when you have very long pieces of data, especially when referring to dialogue. If there is a long sentence the RNN must do a lot of recursions in order to process every single word or rather state. Then there is the problem of vanishing gradient although this we are less observable throughout our project as the scope of our project was not that large. This is a known and is Long-Short Term Memory, a type of Recurrent Neural Network has been developed.
Long-Short Term Memory, even as shown in our project has faster processing speeds. This is because it has the means of forgetting by identifying if a piece of input data changes, instead of doing what a normal RRN does and constantly goes back regardless of what the context of the data being given is.
When deciding how to do the dialogue management when building the chatbot when were considering using the RASA Dialogue Management but had to move away from the toolkit. The reason behind this is although the sophisticated system in place with pre-existing system, using the inbuilt stories and intents within the system, however it was not built in with multiple users in mind. To achieve multi-person dialogue with more than just the chatbot and a single individual would not be able to use Rasa. Rasa was not built with multiple people in mind. This meant there was only the intent and response when developing the dialogue manager.
For it to function it would have to be heavily worked on just to allow for the multiple people to be used. This ignores any issues with developing the dialogue manger that would take place and would be compounded. To use RASA it would have to train on each epoch twice one for each user to prevent it from falling into a pattern based on how second users may act within the training data. Every intent would need to be created twice, once for each user. Alongside the problems once where the Diarization trying to identify the user there would be issues with the trying to work out which intent belong to which user and since they have both had the same set of training data this could cause a great deal of confusion within the system making it next to impossible to separate the different users. This is why we decided to go with building our own system as this way we could alter the fundamental tools that RASA gives us, obviously the main tools would not have been as robust as RASA as that has an entire development team behind it but it is simple unable to achieve what we required from our task at hand.

\subsection{Natural Language Generation}
\label{subsec:nlg}

To make the system feel more unique and less robotic, we made use of Natural Language Generation (NLG) for the phrases that the “host” says to the participants. We used OpenAI's API, specifically “gpt-3.5-turbo”, the same version that is used in ChatGPT. This allowed us to prompt for different outputs for the system that convey the same information. For example, when receiving a correct answer, “Yes, that's it! Well done!” and “You got it! Great job!” are both possible outputs. There are 50 different options for each response the “host” can say.


\section{Evaluation}
\label{sec:evaluation}

\textit{from coursework spec:} evaluation of the system and presentation of the results

\subsection{Methodology}
\label{subsec:methodology}
In this study, we performed extrinsic and intrinsic evaluations. The extrinsic evaluation focused on both subjective and objective measures of the system's performance. The subjective measures included the user's enjoyment and perception of the system's natural behaviour, while the objective measures included the number of turns taken and the agreement rate. Additionally, the correlation between correct answers and enjoyment was also examined. Overall, the evaluation aimed to assess the effectiveness of the system in engaging users and providing accurate responses.

The evaluation focused on intrinsic measures of individual components in a multi-party conversational system. The components were assessed separately, with ASR being evaluated using the word error rate, NLU using precision, recall, accuracy, and F1 score, DM IDK YET, and NLG using n-gram-based overlap with BLEU. The aim was to assess the performance of each component and identify areas of improvement.

Additionally, the evaluation also aimed to test the hypothesis that using verbal cues instead of silence cues in a multi-party conversational system increases user interaction and satisfaction with the system. This hypothesis needed to be statistically proved or disproved through significance testing.
\subsection{Experiment Layout}
\label{subsec:experiment_layout}
The experiment followed a between-subjects design. Every participant was required to read and sign a consent form before they can play the quiz. This was an in-person experiment, with the quiz running on a laptop, where participants can see the questions and the options. Members of the experiment were required to play the quiz at least once. However, they were encouraged to play as many times as they can. After they no longer wished to play, they were asked to complete a questionnaire about their experience. The questionnaire queried them on their experience using a five-point Likert scale.

\subsection{Results}
\label{subsec:results}

\begin{itemize}
  \item ASR results
  \item NLU result
  \item DM result
        NLG result
  \item questionnaire result
\end{itemize}

\section{Conclusion}
\label{sec:conclusion}

\subsection{Ethical Reflection}
\label{subsec:ethics}

\section{Future Work}
\label{sec:future_work}

\textit{from coursework spec:} suggestions for future work

To further improve on NLG within this system, some content moderation could be performed on the generations, to ensure that there are no inappropriate outputs, this can be done entirely within OpenAI's API.  Also, the system could be updated to make use of GPT-4, which at this current time is not publicly available.



\section*{Acknowledgments}
\label{sec:acknowledgments}

The acknowledgments should go immediately before the references.  Do
not number the acknowledgments section. Do not include this section
when submitting your paper for review.

% include your own bib file like this:
%\bibliographystyle{acl}
%\bibliography{acl2016}
\bibliography{references}
\bibliographystyle{acl2016}

\appendix

\section{Supplemental Material, Appendix}
\label{sec:supplemental}


\end{document}
